{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8570d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "class WESADDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe.drop('subject', axis=1)\n",
    "        self.labels = self.dataframe['label'].values\n",
    "        self.dataframe.drop('label', axis=1, inplace=True)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.dataframe.iloc[idx].values\n",
    "        y = self.labels[idx]\n",
    "        return torch.Tensor(x), y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "86fff359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "selected_feats =   [\n",
    "    'BVP_mean', 'BVP_std', 'BVP_min', 'BVP_max',\n",
    "           'EDA_phasic_mean', 'EDA_phasic_std', 'EDA_phasic_min', 'EDA_phasic_max', 'EDA_smna_mean',\n",
    "           'EDA_smna_std', 'EDA_smna_min', 'EDA_smna_max', 'EDA_tonic_mean',\n",
    "           'EDA_tonic_std', 'EDA_tonic_min', 'EDA_tonic_max', 'Resp_mean',\n",
    "           'Resp_std', 'Resp_min', 'Resp_max', 'TEMP_mean', 'TEMP_std', 'TEMP_min',\n",
    "           'TEMP_max', 'TEMP_slope', 'BVP_peak_freq', 'age', 'height',\n",
    "           'weight','subject', 'label'\n",
    "    ]\n",
    "\n",
    "print(len(selected_feats)-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3bf6abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(subject_id, train_batch_size=25, test_batch_size=5):\n",
    "    df = pd.read_csv('data.csv', index_col=0)[selected_feats]\n",
    "\n",
    "    train_df = df[ df['subject'] != subject_id].reset_index(drop=True)\n",
    "    test_df = df[ df['subject'] == subject_id].reset_index(drop=True)\n",
    "    \n",
    "    train_dset = WESADDataset(train_df)\n",
    "    test_dset = WESADDataset(test_df)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dset, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dset, batch_size=test_batch_size)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb0511f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StressNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StressNet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "                        nn.Linear(29, 128),\n",
    "                        #nn.Dropout(0.5),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(128,256 ),\n",
    "                        #nn.Dropout(0.5),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(256, 3),\n",
    "                        #nn.Dropout(0.5),\n",
    "                        nn.LogSoftmax(dim=1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5161fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, validation_loader):\n",
    "    history = {'train_loss': {}, 'train_acc': {}, 'valid_loss': {}, 'valid_acc': {}}\n",
    "    #\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Train:   \n",
    "        total = 0\n",
    "        correct = 0\n",
    "        trainlosses = []\n",
    "\n",
    "        for batch_index, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            # Send to GPU (device)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images.float())\n",
    "\n",
    "            # Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            trainlosses.append(loss.item())\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, argmax = torch.max(outputs, 1)\n",
    "            correct += (labels == argmax).sum().item() #.mean()\n",
    "            total += len(labels)\n",
    "\n",
    "        history['train_loss'][epoch] = np.mean(trainlosses) \n",
    "        history['train_acc'][epoch] = correct/total \n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "\n",
    "                losses = []\n",
    "                total = 0\n",
    "                correct = 0\n",
    "\n",
    "                for images, labels in validation_loader:\n",
    "                    # \n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                    # Forward pass\n",
    "                    outputs = model(images.float())\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Compute accuracy\n",
    "                    _, argmax = torch.max(outputs, 1)\n",
    "                    correct += (labels == argmax).sum().item() #.mean()\n",
    "                    total += len(labels)\n",
    "\n",
    "                    losses.append(loss.item())\n",
    "                    \n",
    "                history['valid_acc'][epoch] = np.round(correct/total, 3)\n",
    "                history['valid_loss'][epoch] = np.mean(losses)\n",
    "\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {np.mean(losses):.4}, Acc: {correct/total:.2}')\n",
    "                \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a75db7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, validation_loader):\n",
    "    print('Evaluating model...')\n",
    "    # Test\n",
    "    model.eval()\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    testlosses = []\n",
    "    correct_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch_index, (images, labels) in enumerate(validation_loader):\n",
    "            # Send to GPU (device)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images.float())\n",
    "\n",
    "            # Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            testlosses.append(loss.item())\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, argmax = torch.max(outputs, 1)\n",
    "            correct += (labels == argmax).sum().item() #.mean()\n",
    "            total += len(labels)\n",
    "\n",
    "            correct_labels.extend(labels)\n",
    "            predictions.extend(argmax)\n",
    "\n",
    "\n",
    "    test_loss = np.mean(testlosses)\n",
    "    accuracy = np.round(correct/total, 2)\n",
    "    print(f'Loss: {test_loss:.4}, Acc: {accuracy:.2}')\n",
    "    \n",
    "    y_true = [label.item() for label in correct_labels]\n",
    "    y_pred = [label.item() for label in predictions]\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # TODO: return y true and y pred, make cm after ( use ytrue/ypred for classification report)\n",
    "    # return [y_true, y_pred, test_loss, accuracy]\n",
    "    return cm, test_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7000ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subject:  2\n",
      "Epoch [1/100], Loss: 1.183, Acc: 0.45\n",
      "Epoch [11/100], Loss: 0.8169, Acc: 0.75\n",
      "Epoch [21/100], Loss: 0.892, Acc: 0.74\n",
      "Epoch [31/100], Loss: 0.7297, Acc: 0.75\n",
      "Epoch [41/100], Loss: 0.7408, Acc: 0.75\n",
      "Epoch [51/100], Loss: 1.146, Acc: 0.72\n",
      "Epoch [61/100], Loss: 0.7601, Acc: 0.75\n",
      "Epoch [71/100], Loss: 0.7289, Acc: 0.78\n",
      "Epoch [81/100], Loss: 0.9878, Acc: 0.64\n",
      "Epoch [91/100], Loss: 1.001, Acc: 0.74\n",
      "Evaluating model...\n",
      "Loss: 0.7061, Acc: 0.79\n",
      "\n",
      "Subject:  3\n",
      "Epoch [1/100], Loss: 1.251, Acc: 0.22\n",
      "Epoch [11/100], Loss: 1.012, Acc: 0.55\n",
      "Epoch [21/100], Loss: 1.123, Acc: 0.39\n",
      "Epoch [31/100], Loss: 1.17, Acc: 0.57\n",
      "Epoch [41/100], Loss: 0.9934, Acc: 0.6\n",
      "Epoch [51/100], Loss: 0.5383, Acc: 0.74\n",
      "Epoch [61/100], Loss: 1.114, Acc: 0.53\n",
      "Epoch [71/100], Loss: 1.069, Acc: 0.56\n",
      "Epoch [81/100], Loss: 1.316, Acc: 0.49\n",
      "Epoch [91/100], Loss: 1.328, Acc: 0.6\n",
      "Evaluating model...\n",
      "Loss: 0.7318, Acc: 0.7\n",
      "\n",
      "Subject:  4\n",
      "Epoch [1/100], Loss: 1.548, Acc: 0.54\n",
      "Epoch [11/100], Loss: 0.6615, Acc: 0.83\n",
      "Epoch [21/100], Loss: 0.5953, Acc: 0.82\n",
      "Epoch [31/100], Loss: 0.8102, Acc: 0.83\n",
      "Epoch [41/100], Loss: 0.7208, Acc: 0.79\n",
      "Epoch [51/100], Loss: 1.049, Acc: 0.78\n",
      "Epoch [61/100], Loss: 0.7268, Acc: 0.82\n",
      "Epoch [71/100], Loss: 1.115, Acc: 0.83\n",
      "Epoch [81/100], Loss: 1.538, Acc: 0.83\n",
      "Epoch [91/100], Loss: 0.9503, Acc: 0.8\n",
      "Evaluating model...\n",
      "Loss: 0.6416, Acc: 0.82\n",
      "\n",
      "Subject:  5\n",
      "Epoch [1/100], Loss: 1.152, Acc: 0.49\n",
      "Epoch [11/100], Loss: 0.5307, Acc: 0.82\n",
      "Epoch [21/100], Loss: 0.808, Acc: 0.8\n",
      "Epoch [31/100], Loss: 0.4155, Acc: 0.82\n",
      "Epoch [41/100], Loss: 0.4185, Acc: 0.84\n",
      "Epoch [51/100], Loss: 0.5899, Acc: 0.8\n",
      "Epoch [61/100], Loss: 0.4343, Acc: 0.78\n",
      "Epoch [71/100], Loss: 0.5468, Acc: 0.77\n",
      "Epoch [81/100], Loss: 0.4777, Acc: 0.85\n",
      "Epoch [91/100], Loss: 0.4493, Acc: 0.78\n",
      "Evaluating model...\n",
      "Loss: 0.498, Acc: 0.82\n",
      "\n",
      "Subject:  6\n",
      "Epoch [1/100], Loss: 0.969, Acc: 0.54\n",
      "Epoch [11/100], Loss: 0.4181, Acc: 0.88\n",
      "Epoch [21/100], Loss: 0.4883, Acc: 0.86\n",
      "Epoch [31/100], Loss: 0.3504, Acc: 0.83\n",
      "Epoch [41/100], Loss: 0.3852, Acc: 0.85\n",
      "Epoch [51/100], Loss: 0.4343, Acc: 0.87\n",
      "Epoch [61/100], Loss: 0.3918, Acc: 0.83\n",
      "Epoch [71/100], Loss: 1.172, Acc: 0.59\n",
      "Epoch [81/100], Loss: 1.176, Acc: 0.59\n",
      "Epoch [91/100], Loss: 0.3678, Acc: 0.9\n",
      "Evaluating model...\n",
      "Loss: 0.9373, Acc: 0.68\n",
      "\n",
      "Subject:  7\n",
      "Epoch [1/100], Loss: 0.9237, Acc: 0.63\n",
      "Epoch [11/100], Loss: 0.4545, Acc: 0.82\n",
      "Epoch [21/100], Loss: 0.3085, Acc: 0.92\n",
      "Epoch [31/100], Loss: 0.5191, Acc: 0.68\n",
      "Epoch [41/100], Loss: 0.3914, Acc: 0.87\n",
      "Epoch [51/100], Loss: 0.4481, Acc: 0.86\n",
      "Epoch [61/100], Loss: 0.508, Acc: 0.82\n",
      "Epoch [71/100], Loss: 0.6566, Acc: 0.68\n",
      "Epoch [81/100], Loss: 0.5111, Acc: 0.73\n",
      "Epoch [91/100], Loss: 0.6935, Acc: 0.59\n",
      "Evaluating model...\n",
      "Loss: 0.5171, Acc: 0.63\n",
      "\n",
      "Subject:  8\n",
      "Epoch [1/100], Loss: 0.9354, Acc: 0.62\n",
      "Epoch [11/100], Loss: 0.54, Acc: 0.8\n",
      "Epoch [21/100], Loss: 0.485, Acc: 0.8\n",
      "Epoch [31/100], Loss: 0.4847, Acc: 0.78\n",
      "Epoch [41/100], Loss: 0.4497, Acc: 0.81\n",
      "Epoch [51/100], Loss: 0.3895, Acc: 0.81\n",
      "Epoch [61/100], Loss: 0.4299, Acc: 0.81\n",
      "Epoch [71/100], Loss: 0.7123, Acc: 0.63\n",
      "Epoch [81/100], Loss: 0.3468, Acc: 0.86\n",
      "Epoch [91/100], Loss: 0.3705, Acc: 0.82\n",
      "Evaluating model...\n",
      "Loss: 0.3548, Acc: 0.81\n",
      "\n",
      "Subject:  9\n",
      "Epoch [1/100], Loss: 0.7911, Acc: 0.63\n",
      "Epoch [11/100], Loss: 0.2455, Acc: 0.91\n",
      "Epoch [21/100], Loss: 0.2803, Acc: 0.85\n",
      "Epoch [31/100], Loss: 0.2664, Acc: 0.82\n",
      "Epoch [41/100], Loss: 0.2278, Acc: 0.91\n",
      "Epoch [51/100], Loss: 0.1832, Acc: 0.94\n",
      "Epoch [61/100], Loss: 0.2271, Acc: 0.9\n",
      "Epoch [71/100], Loss: 0.1397, Acc: 0.97\n",
      "Epoch [81/100], Loss: 0.1807, Acc: 0.96\n",
      "Epoch [91/100], Loss: 0.2197, Acc: 0.94\n",
      "Evaluating model...\n",
      "Loss: 0.2961, Acc: 0.85\n",
      "\n",
      "Subject:  10\n",
      "Epoch [1/100], Loss: 1.009, Acc: 0.49\n",
      "Epoch [11/100], Loss: 0.4947, Acc: 0.81\n",
      "Epoch [21/100], Loss: 0.3929, Acc: 0.84\n",
      "Epoch [31/100], Loss: 0.569, Acc: 0.84\n",
      "Epoch [41/100], Loss: 0.4921, Acc: 0.83\n",
      "Epoch [51/100], Loss: 0.8117, Acc: 0.67\n",
      "Epoch [61/100], Loss: 0.5727, Acc: 0.81\n",
      "Epoch [71/100], Loss: 0.6588, Acc: 0.84\n",
      "Epoch [81/100], Loss: 0.4699, Acc: 0.78\n",
      "Epoch [91/100], Loss: 0.4787, Acc: 0.78\n",
      "Evaluating model...\n",
      "Loss: 0.3646, Acc: 0.8\n",
      "\n",
      "Subject:  11\n",
      "Epoch [1/100], Loss: 1.025, Acc: 0.52\n",
      "Epoch [11/100], Loss: 0.693, Acc: 0.67\n",
      "Epoch [21/100], Loss: 0.7222, Acc: 0.61\n",
      "Epoch [31/100], Loss: 0.6767, Acc: 0.67\n",
      "Epoch [41/100], Loss: 0.5346, Acc: 0.76\n",
      "Epoch [51/100], Loss: 0.5532, Acc: 0.75\n",
      "Epoch [61/100], Loss: 0.492, Acc: 0.81\n",
      "Epoch [71/100], Loss: 0.566, Acc: 0.81\n",
      "Epoch [81/100], Loss: 0.5431, Acc: 0.77\n",
      "Epoch [91/100], Loss: 0.5921, Acc: 0.81\n",
      "Evaluating model...\n",
      "Loss: 0.6262, Acc: 0.75\n",
      "\n",
      "Subject:  13\n",
      "Epoch [1/100], Loss: 0.9234, Acc: 0.67\n",
      "Epoch [11/100], Loss: 0.7572, Acc: 0.62\n",
      "Epoch [21/100], Loss: 0.3845, Acc: 0.81\n",
      "Epoch [31/100], Loss: 0.4026, Acc: 0.85\n",
      "Epoch [41/100], Loss: 0.486, Acc: 0.82\n",
      "Epoch [51/100], Loss: 0.7046, Acc: 0.62\n",
      "Epoch [61/100], Loss: 0.4597, Acc: 0.84\n",
      "Epoch [71/100], Loss: 0.9049, Acc: 0.65\n",
      "Epoch [81/100], Loss: 1.338, Acc: 0.7\n",
      "Epoch [91/100], Loss: 0.8187, Acc: 0.71\n",
      "Evaluating model...\n",
      "Loss: 0.9714, Acc: 0.71\n",
      "\n",
      "Subject:  14\n",
      "Epoch [1/100], Loss: 0.9159, Acc: 0.57\n",
      "Epoch [11/100], Loss: 0.7547, Acc: 0.77\n",
      "Epoch [21/100], Loss: 0.8746, Acc: 0.76\n",
      "Epoch [31/100], Loss: 1.032, Acc: 0.76\n",
      "Epoch [41/100], Loss: 1.915, Acc: 0.76\n",
      "Epoch [51/100], Loss: 2.103, Acc: 0.77\n",
      "Epoch [61/100], Loss: 1.849, Acc: 0.71\n",
      "Epoch [71/100], Loss: 1.87, Acc: 0.68\n",
      "Epoch [81/100], Loss: 1.518, Acc: 0.78\n",
      "Epoch [91/100], Loss: 1.853, Acc: 0.75\n",
      "Evaluating model...\n",
      "Loss: 1.897, Acc: 0.8\n",
      "\n",
      "Subject:  15\n",
      "Epoch [1/100], Loss: 0.8852, Acc: 0.56\n",
      "Epoch [11/100], Loss: 0.3997, Acc: 0.85\n",
      "Epoch [21/100], Loss: 0.3221, Acc: 0.92\n",
      "Epoch [31/100], Loss: 0.187, Acc: 0.94\n",
      "Epoch [41/100], Loss: 0.2014, Acc: 0.94\n",
      "Epoch [51/100], Loss: 0.1823, Acc: 0.92\n",
      "Epoch [61/100], Loss: 0.2364, Acc: 0.94\n",
      "Epoch [71/100], Loss: 0.4483, Acc: 0.8\n",
      "Epoch [81/100], Loss: 0.2269, Acc: 0.92\n",
      "Epoch [91/100], Loss: 0.2015, Acc: 0.9\n",
      "Evaluating model...\n",
      "Loss: 0.3887, Acc: 0.87\n",
      "\n",
      "Subject:  16\n",
      "Epoch [1/100], Loss: 1.126, Acc: 0.54\n",
      "Epoch [11/100], Loss: 0.3401, Acc: 0.91\n",
      "Epoch [21/100], Loss: 0.2225, Acc: 0.95\n",
      "Epoch [31/100], Loss: 0.5058, Acc: 0.81\n",
      "Epoch [41/100], Loss: 0.251, Acc: 0.92\n",
      "Epoch [51/100], Loss: 0.2046, Acc: 0.95\n",
      "Epoch [61/100], Loss: 0.2757, Acc: 0.92\n",
      "Epoch [71/100], Loss: 0.3961, Acc: 0.9\n",
      "Epoch [81/100], Loss: 0.2399, Acc: 0.95\n",
      "Epoch [91/100], Loss: 0.163, Acc: 0.96\n",
      "Evaluating model...\n",
      "Loss: 0.1538, Acc: 0.96\n",
      "\n",
      "Subject:  17\n",
      "Epoch [1/100], Loss: 1.086, Acc: 0.44\n",
      "Epoch [11/100], Loss: 1.274, Acc: 0.47\n",
      "Epoch [21/100], Loss: 1.475, Acc: 0.43\n",
      "Epoch [31/100], Loss: 1.092, Acc: 0.46\n",
      "Epoch [41/100], Loss: 1.174, Acc: 0.49\n",
      "Epoch [51/100], Loss: 1.749, Acc: 0.54\n",
      "Epoch [61/100], Loss: 1.387, Acc: 0.6\n",
      "Epoch [71/100], Loss: 1.377, Acc: 0.57\n",
      "Epoch [81/100], Loss: 1.396, Acc: 0.52\n",
      "Epoch [91/100], Loss: 1.027, Acc: 0.58\n",
      "Evaluating model...\n",
      "Loss: 1.179, Acc: 0.59\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 25\n",
    "test_batch_size = 5\n",
    "\n",
    "# Learning Rate\n",
    "learning_rate = 5e-3\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Number of Epochs\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "df = pd.read_csv('data.csv', index_col=0)[selected_feats]\n",
    "subject_id_list = df['subject'].unique()\n",
    "\n",
    "# models = [] # save models at all/ directly?\n",
    "y_preds = []\n",
    "y_truths = []\n",
    "histories = []\n",
    "confusion_matrices = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "\n",
    "for _ in subject_id_list:\n",
    "    print('\\nSubject: ', _)\n",
    "    model = StressNet().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_loader, test_loader = get_data_loaders(_)  # Pass batch sizes here\n",
    "    \n",
    "    history = train(model, optimizer, train_loader, test_loader)\n",
    "    histories.append(history)\n",
    "    \n",
    "    cm, test_loss, test_acc = test(model, test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(test_acc)\n",
    "    confusion_matrices.append(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ea1d4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7719999999999999"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7158c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
